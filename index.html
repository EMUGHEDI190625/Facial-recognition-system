<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>ECN Face Recognition System</title>

<script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

<style>
body{
  text-align:center;
  font-family:Arial;
  background:#111;
  color:white;
}

video{
  border:3px solid lime;
  border-radius:10px;
}

button{
  padding:12px 25px;
  font-size:18px;
  margin-top:15px;
  border:none;
  border-radius:8px;
  background:lime;
  font-weight:bold;
  cursor:pointer;
}
</style>
</head>

<body>

<h1>ECN Face Recognition Capture</h1>

<video id="video" width="720" height="560" autoplay muted playsinline></video>

<br>
<button onclick="capture()">Capture Face</button>

<canvas id="snapshot" width="720" height="560" style="display:none;"></canvas>

<script>
const video = document.getElementById("video")
console.log(navigator.mediaDevices)


// ================= LOAD MODELS =================
Promise.all([
 faceapi.nets.ssdMobilenetv1.loadFromUri('models'),
 faceapi.nets.faceLandmark68Net.loadFromUri('models'),
 faceapi.nets.faceRecognitionNet.loadFromUri('models')
]).then(startCamera)


// ================= START CAMERA =================
async function startCamera(){

 try{

   const stream = await navigator.mediaDevices.getUserMedia({
     video:{
       facingMode:"user"
     },
     audio:false
   })

   video.srcObject = stream
   video.play()

 }catch(err){
   alert("Camera access denied or not supported: " + err)
 }

}



// ================= FACE DETECTION =================
video.addEventListener("play",()=>{

 const canvas = faceapi.createCanvasFromMedia(video)
 document.body.append(canvas)

 const displaySize = {
   width:video.width,
   height:video.height
 }

 faceapi.matchDimensions(canvas,displaySize)

 setInterval(async()=>{

   const detections = await faceapi.detectAllFaces(
       video,
       new faceapi.SsdMobilenetv1Options()
   ).withFaceLandmarks().withFaceDescriptors()

   const resized = faceapi.resizeResults(detections,displaySize)

   canvas.getContext("2d").clearRect(0,0,canvas.width,canvas.height)

   faceapi.draw.drawDetections(canvas,resized)
   faceapi.draw.drawFaceLandmarks(canvas,resized)

 },100)
})


// ================= CAPTURE IMAGE =================
function capture(){

 const canvas = document.getElementById("snapshot")
 const ctx = canvas.getContext("2d")

 ctx.drawImage(video,0,0,canvas.width,canvas.height)

 const imageURL = canvas.toDataURL("image/png")

 console.log("Captured Image Link:")
 console.log(imageURL)

 alert("Face Captured Successfully!")

 // OPTIONAL â€” send to Google Sheet
 // sendToSheet(imageURL)
}



// ================= SEND TO GOOGLE SHEET =================
// Replace URL with your Google Script Web App URL
function sendToSheet(img){

 fetch("YOUR_GOOGLE_SCRIPT_URL",{
   method:"POST",
   body:JSON.stringify({image:img})
 })

}
</script>

</body>
</html>



